{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means: Agrupación sobre dataset sintético por K-means\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset de agrupación sintético.\n",
    "- Preprocesar los datos.\n",
    "- Implementar el algoritmo de agrupación no-supervisado de K-means.\n",
    "- Comprobar nuestra implementación.\n",
    "- Entrenar un modelo de K-means con múltiples inicializaciones.\n",
    "- Evaluar el modelo y representar sus resultados gráficamente.\n",
    "- Escoger un nº de clústeres óptimo por la regla del codo.\n",
    "\n",
    "\n",
    "En este ejercicio vamos a implementar un algoritmo de entrenamiento de modelos de agrupación por K-means.\n",
    "\n",
    "Para ello, vamos a crear un dataset sintético de agrupación, vamos a desarrollar nuestra implementación de K-means y vamos a comprobarla.\n",
    "\n",
    "Como sabemos, los modelos de agrupación son muy sensibles a las condiciones de inicialización, por lo que vamos a entrenar varios modelos en paralelo y comprobar gráficamente si sus resultados son notablemente diferentes.\n",
    "\n",
    "Para evaluarlos, vamos a hacerlo de una forma gráfica, representando el resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear el dataset sintético\n",
    "\n",
    "Vamos a crear un dataset sintético de clasificación. Este dataset tendrá un nº determinado de clústeres con un nº de ejemplos y una desviación típica asociada.\n",
    "\n",
    "Para hacerlo más sencillo, puedes utilizar la función de [sklearn.datasets.make_blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crea un dataset sintético de agrupación\n",
    "# Usa los siguientes parámetros para crearlo\n",
    "n_samples = 1000\n",
    "n_features = 2\n",
    "centers = 5\n",
    "cluster_std = [1.0, 1.5, 0.5, 2.0, 2.5]\n",
    "return_centers = True\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Preprocesa los datos con los pasos habituales, si es necesario:\n",
    "\n",
    "- Reordenar los datos aleatoriamente.\n",
    "- Normalizar los datos.\n",
    "\n",
    "Como la agrupación es un modelo de aprendizaje no supervisado, no lo evaluaremos por el método tradicional, comparando sus resultados con unos resultados previamente conocidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los datos si es necesario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar el algoritmo de K-means\n",
    "\n",
    "Ahora, implementa el algoritmo de agrupación de K-means.\n",
    "\n",
    "Recuerda los pasos del algoritmo:\n",
    "1. Define el nº de clústeres a considerar.\n",
    "1. Inicializamos los centroides de cada clúster, p. ej. escogiendo los primeros ejemplos del dataset.\n",
    "1. Asignamos cada ejemplo del dataset a su centroide más cercano.\n",
    "1. Calculamos el punto medio en el espacio n-dimensional del dataset para cada clúster\n",
    "1. Actualizamos el centroide correspondiente a dicho punto.\n",
    "1. Re-asignamos cada ejemplo a su centroide más cercano.\n",
    "1. Continuamos iterando hasta que el entrenamiento converge: los centroides no varían de posición o lo hacen menos que una tolerancia, o alcanzamos el nº máx. de iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa una función auxiliar para calcular la distancia entre los ejemplos y un punto dado\n",
    "def dist_examples(x, centroide):\n",
    "    \"\"\" Calcula la distancia entre el punto x y el centroide en el espacio n-dimensional\n",
    "    \n",
    "    Argumentos:\n",
    "    x -- array de Numpy n-dimensional con las características del ejemplo\n",
    "    centroide -- array de Numpy n-dimensional con el punto del centroide\n",
    "    \n",
    "    Devuelve:\n",
    "    dist -- distancia euclídea en el espacio n-dimensional entre x y el centroide\n",
    "    \"\"\"\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa el algoritmo de agrupación por K-means\n",
    "n_clusters = 5\n",
    "n_iter = 100\n",
    "tol = 1e-3\n",
    "\n",
    "# Inicializa los centroides como un array 2D con la posición n-dimensional de los n_clusters primeros ejemplos, tamaño n_clusters x n\n",
    "centroides = [...]\n",
    "\n",
    "# Itera sobre el nº máx de iteraciones\n",
    "for i in range(n_iter):\n",
    "    # Asigna cada ejemplo a su centroide más cercano usando dist_examples()\n",
    "    for m in n_samples:\n",
    "        cluster_asignado_ejemplos = [...]    # tamaño m, valores [1, n_clusters]\n",
    "    \n",
    "    # Calcula el punto medio n-dimensional para cada clúster con sus ejemplos asignados\n",
    "    for c in n_clusters:\n",
    "        for n in n_features:\n",
    "            # Consejo: Puedes usar las funciones de Numpy para calcular la media de un array o un slice del mismo\n",
    "            centroide[...] = [...]\n",
    "    \n",
    "        # Actualiza el centroide de cada clúster a dicho punto medio\n",
    "        centroides[...] = centroide\n",
    "\n",
    "    # Comprueba si el modelo converge: todos los centroides se mueven menos de la tolerancia tol\n",
    "    if [...]:\n",
    "        print('Modelo converge en iteración nº:', i)\n",
    "        \n",
    "        break\n",
    "else:\n",
    "    print('Nº máx. de iteraciones alcanzado')\n",
    "    \n",
    "print('Centroides finales:')\n",
    "print(centroides)\n",
    "\n",
    "print('Centroides asignados a cada ejemplo:')\n",
    "print(cluster_asignado_ejemplos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Recuerda que las celdas de plantilla de código son siempre símplemente guías propuestas para implementar tu código. Si prefieres modificarlas para desarrollar tu código con otra estructura, puedes hacerlo en cualquier momento. Lo único importante es que el cálculo final sea correcto y que devuelva los resultados finales a revisar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar y representar los resultados\n",
    "\n",
    "Vamos a representar una gráfica 2D con los resultados de nuestro entrenamiento: el centroide de cada clúster y los ejemplos asignados a cada uno.\n",
    "Del mismo modo, vamos a usar unas métricas de evaluación adecuadas para agrupación (notablemente diferentes de las usadas para clasificación).\n",
    "\n",
    "Para ello, puedes tener como referencia este ejemplo: [A demo of K-Means clustering on the handwritten digits data](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html).\n",
    "\n",
    "Al crear el dataset original hemos recuperado el centroide de cada clúster utilizado para crearlo, la *ground truth* de este dataset, que podemos usar en esta evaluación.\n",
    "\n",
    "En nuestro caso, coincide que nuestro *n*, nº de dimensiones o *n_features* es también de 2, por lo que no tenemos que reducir la dimensionalidad por PCA (introduciremos este concepto de ML en una sesión posterior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa tu modelo con las métricas de homogeneidad, completación, V-measure, índice Rand ajustado, índice de información mútua ajustado y el coeficiente de silueta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Aprovecha la oportunidad para bucear en la documentación y conocer mejor estos coeficientes, utilizados para evaluar la agrupación, diferentes de los usados en clasificación: [Clustering performance evaluation](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa tu modelo entrenado: los centroides de cada clúster y los ejemplos asignados a cada uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonus*: *¿Puedes calcular la distancia total entre cada centroide entrenado y el centroide original correspondiente?* Cuidado, no tiene por qué ser el más cercano (2 centroides entrenados pueden tener el mismo centroide original como el más cercano.\n",
    "\n",
    "*¿Y si representas también esos centroides en la celda con los resultados de tu modelo, en otro color?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula la distancia entre cada centroide entrenado y el centroide original correspondiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar un modelo de K-means con múltiples incializaciones\n",
    "\n",
    "Como decíamos, la agrupación por K-means es un algoritmo bastante sensible a la inicialización utilizada, puesto que el resultado final puede variar.\n",
    "Para comprobarlo gráficamente, reentrena de nuevo el modelo, escogiendo unos centroides iniciales diferentes, esta vez de forma aleatoria entre los diferentes ejemplos del dataset.\n",
    "\n",
    "Para ello, copia abajo las celdas de código que entrenan el modelo (modificando la elección de los centroides originales), lo evalúan y representan los resultados gráficamente. De esta forma podrás ver los resultados en ambos casos a la vez para compararlos.\n",
    "\n",
    "*Nota*: Para la representación gráfica, cambia el nº de figura en *plt.figure(1)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa el algoritmo de agrupación por K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa tu modelo con las métricas de homogeneidad, completación, V-measure, índice Rand ajustado, índice de información mútua ajustado y el coeficiente de silueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa tu modelo entrenado: los centroides de cada clúster y los ejemplos asignados a cada uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo varían los resultados de tu modelo con otra inicialización aleatoria, sus métricas de evaluación y la gráfica de resultados? ¿Cómo varían si reentrenas el modelo con inicializaciones aleatorias varias veces?*\n",
    "\n",
    "También puedes recrear el dataset original, incluso cambiando el tamaño o desviación típica de cada clúster, y ver si afecta a los resultados y a la varianción entre los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escoger el nº óptimo de clústeres\n",
    "\n",
    "Al haber creado un dataset sintético, hemos escogido nosotros el nº de clústeres \"correcto\" para el mismo. Sin embargo, en un dataset real no conoceremos dicho nº de clústeres, e incluso en muchas ocasiones no habrá un nº de clústeres correcto, puesto que encontrar la separación entre un clúster u otro, si están muy cerca, puede ser una tarea no trivial y subjetiva.\n",
    "\n",
    "Por lógica matemática, a menor nº de clústeres, más distancia media habrá entre cada ejemplo y su clúster asignado, y a mayor nº de clústeres, menos distancia. En una reducción al absurdo, cuando usamos un nº de clústeres igual al nº de ejemplos, cada centroide idealmente corresponderá a la posición de cada ejemplo, y la distancia media al clúster más cercano será 0.\n",
    "\n",
    "Por tanto, para escoger el nº óptimo de clústeres, cuando no tenemos ninguna consideración o limitación externa, podemos utilizar la llamada \"regla del codo\".\n",
    "\n",
    "Vamos a aplicar dicha regla para nuestro dataset:\n",
    "1. Entrena un modelo para cada nº de clústeres a considerar en un rango, p. ej. [1, 10]\n",
    "1. Para cada nº de clústeres, entrenamos varios modelos con múltiples inicializaciones aleatorias, y escogemos el de mejor métrica de evaluación\n",
    "1. Representamos gráficamente la métrica de evaluación del mejor modelo vs el nº de clústeres considerado\n",
    "1. Escogemos como nº de clústeres \"óptimo\" aquel donde hay un \"codo\" en la gráfica, donde más abruptamente cambie la tendencia o pendiente.\n",
    "\n",
    "En un dataset real no contaremos con su *ground truth*, los centroides correctos, por lo que como evaluación utilizaremos la métrica del coeficiente de silueta.\n",
    "\n",
    "Implementa la regla del codo para escoger un nº óptimo de clústeres para este dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la regla del codo para escoger un nº óptimo de clústeres\n",
    "n_clusters = [...]    # Array [1, 2, 3, ..., 10]\n",
    "n_iter = 100\n",
    "tol = 1e-3\n",
    "\n",
    "# Itera sobre el nº de clústeres a considerar\n",
    "for n_c in n_clusters:\n",
    "    # Entrena varios modelos con inicializaciones aleatorias\n",
    "    for _ in range(5):\n",
    "        # Evalúa cada modelo por el coeficiente de silueta y quédate con el mejor\n",
    "        # Pseudo-código\n",
    "        if evaluacion > mejor_evaluacion:\n",
    "            mejor_modelo = modelo\n",
    "            \n",
    "            # Usa tu código modificado de celdas anteriores para entrenar los modelos\n",
    "            \n",
    "# Como resultado final buscamos:\n",
    "print('Centroides de cada modelo, según el nº de clústeres:')\n",
    "print()\n",
    "\n",
    "print('Coeficiente de silueta de cada modelo, según el nº de clústeres:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente la regla del codo en una gráfica de líneas: coeficiente de silueta del mejor modelo vs nº de clústeres considerados\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Y si cambiamos el nº de clústeres originales del dataset? ¿Sigue apreciándose el nº óptimo en la gráfica con la misma claridad?*\n",
    "\n",
    "Modifica el dataset original y la resolución de la regla del codo para compararlo. Usa varios nº de clústeres, como 5 de nuevo, 2, 4 y 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escoge un nº de clústeres óptimo en tu último resultado e indícalo en esta celda:\n",
    "\n",
    "- Nº de clústeres óptimo por la regla del codo: X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, representa de nuevo gráficamente los resultados del modelo seleccionado, con el nº de clústeres óptimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa tu modelo entrenado: los centroides de cada clúster y los ejemplos asignados a cada uno"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
