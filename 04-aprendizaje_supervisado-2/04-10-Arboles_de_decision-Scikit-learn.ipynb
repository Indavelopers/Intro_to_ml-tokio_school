{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión: Scikit-learn\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Entrenar un modelo de regresión lineal por árboles de decisión\n",
    "- Detectar si se produce desviación o sobreajuste en el modelo\n",
    "- Optimizar los hiper-parámetros con validación cruzada\n",
    "- Evaluarlo sobre el subset de test\n",
    "\n",
    "Vamos a resolver un problema de regresión lineal multivariable similar al de ejercicios anteriores, pero esta vez usando un árbol de decisión para regresión lineal.\n",
    "\n",
    "Un ejemplo que puedes tener como referencia para este ejercicio: [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar un dataset sintético\n",
    "\n",
    "Genera un dataset sintético con un término de error algo acusado y pocas características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético para regresión lineal con un término de error notable\n",
    "\n",
    "m = 1000\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el dataset para asegurarte que el término de error es suficientemente alto\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "plt.scatter([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "- Reordena los datos aleatoriamente.\n",
    "- Normalízalos.\n",
    "- Divídelos en subsets de entrenamiento y test.\n",
    "\n",
    "*Nota*: De nuevo usaremos K-fold para la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset en subset de entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrena un modelo inicial\n",
    "\n",
    "Vamos a comenzar a explorar los modelos de árboles de decisión para regresión con un modelo inicial.\n",
    "\n",
    "Para ello, entrena un modelo de [sklearn.tree.DecissionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) sobre el subset de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un árbol de regresión sobre el subset de entrenamiento con máx. profundidad de 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comprueba la idoneidad del modelo evaluándolo sobre el subset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE y R^2 sobre el subset de test\n",
    "\n",
    "y_test_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: %.2f', mse)\n",
    "print('Coeficiente de determinación: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Crees que se da desviación o sobreajuste en dicho modelo?* Para ello, compara su precisión con la calculada sobre el subset de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE y R^2 ahora sobre el subset de entrenamiento\n",
    "\n",
    "y_train_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: %.2f', mse)\n",
    "print('Coeficiente de determinación: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como decíamos, los árboles de decisión tienden a sobreajustar, a ajustarse demasiado a los datos usados para entrenarlo y a veces no poder predecir bien sobre nuevos ejemplos.\n",
    "\n",
    "Vamos a comprobarlo gráficamente entrenando otro modelo con una profundidad máxima mucho mayor, de 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena otro árbol de regresión sobre el subset de entrenamiento con máx. profundidad de 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE y R^2 sobre el subset de entrenamiento\n",
    "\n",
    "y_train_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: %.2f', mse)\n",
    "print('Coeficiente de determinación: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compara la precisión del entrenamiento de este modelo con el anterior (sobre el subset de entrenamiento).\n",
    "\n",
    "*¿Es mayor o menor al aumentar la profundidad máxima del árbol?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a representar gráficamente ambos modelos, para comprobar si sufren desviación o sobreajuste.\n",
    "\n",
    "Para hacerlo, puedes guiarte por el ejemplo anterior: [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente las predicciones de ambos modelos\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representa en un gráfico de puntos el subset de entrenamiento\n",
    "plt.scatter([...])\n",
    "# Representa en un gráfico de puntos el subset de test, con un color diferente\n",
    "plt.scatter([...])\n",
    "\n",
    "# Representa en un gráfico de líneas las predicciones de ambos modelos, con colores diferentes y una leyenda\n",
    "# para distinguirlos\n",
    "# Como eje horizontal, usa un espacio lineal de un gran nº de elementos entre el valor máx. y mín. de X\n",
    "x_axis = [...]\n",
    "\n",
    "plt.plot([...])\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos podido comprobar, generalmente una profundidad máx. demasiado pequeña lleva a un modelo con desviación, un modelo que no es capaz de ajustar suficientemente bien la curva, mientras que una profundidad máx. demasiado alta lleva a un modelo con sobreajuste, un modelo que ajusta demasiado bien la curva, pero que no tiene una buena precisión en ejemplos futuros.\n",
    "\n",
    "Por tanto, en cuanto a árboles de regresión tenemos un hiper-parámetro, la profundidad máxima, que debemos optimizar por validación cruzada. También hay otros hiper-parámetros, como el criterio para medir la calidad de una división, la estrategia para crear esa división, el nº mín. de ejemplos necesario para dividir un nodo, etc., etc.\n",
    "\n",
    "Por simpleza, vamos a comenzar realizando la validación cruzada sólo para hallar el valor óptimo de la profunidad máxima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo diferente para cada valor de *max_depth* considerado sobre un fold diferente\n",
    "\n",
    "# Valores de max_depth a considerar\n",
    "max_depths = list(range(1:8))\n",
    "print('Profundidades máx. a considerar:')\n",
    "print(max_depths)\n",
    "\n",
    "# Crea x splits de K-fold, uno por cada valor de max_depth a considerar\n",
    "kf = [...]\n",
    "\n",
    "# Itera sobre los splits, entrena tus modelos y evalúalos sobre el subset de CV generado\n",
    "linear_models = []\n",
    "best_model = None\n",
    "for train, cv in kf.split(X):\n",
    "    # Entrena un modelo sobre el subset train\n",
    "    # Evalúalo sobre el subset cv usando su método score()\n",
    "    # Guarda el modelo con el mejor score en la variable best_model y muestra el alpha del mejor modelo\n",
    "    alpha = [...]\n",
    "    print('Profundidad máx. usada:', max_depth)\n",
    "    \n",
    "    linear_models[...] = [...]\n",
    "    \n",
    "    # Si el modelo es mejor que el mejor modelo hasta ahora...\n",
    "    best_model = [...]\n",
    "    print('Profundidad máx. del mejor árbol hasta ahora:', max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo sobre el subset de test.\n",
    "\n",
    "Para ello, calcula sus métricas de MSE y R^2 score y representa gráficamente las predicciones del modelo vs el subset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE y R^2 sobre el subset de test\n",
    "\n",
    "y_train_test = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: %.2f', mse)\n",
    "print('Coeficiente de determinación: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente las predicciones del mejor árbol sobre el subset de test\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representa en un gráfico de puntos el subset de test\n",
    "plt.scatter([...])\n",
    "\n",
    "# Representa en un gráfico de líneas las predicciones del modelo\n",
    "# Como eje horizontal, usa un espacio lineal de un gran nº de elementos entre el valor máx. y mín. de X_test\n",
    "x_axis = [...]\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
