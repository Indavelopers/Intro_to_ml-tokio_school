{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal: Normalización\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético con características en diferentes rangos de valores\n",
    "- Entrenar un modelo de regresión lineal sobre el dataset original\n",
    "- Normalizar el dataset original\n",
    "- Entrenar otro modelo de regresión lineal sobre el dataset normalizado\n",
    "- Comparar el entrenamiento de ambos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del dataset sintético\n",
    "\n",
    "Vamos a crear de nuevo un dataset sintético para regresión lineal por el método manual.\n",
    "\n",
    "Crea un dataset sintético con un término de error del 10% del valor de *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia el código de ejercicios anteriores para generar un dataset con término de bias y error\n",
    "\n",
    "m = 1000\n",
    "n = 4\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_verd = [...]\n",
    "\n",
    "error = 0.1\n",
    "\n",
    "Y = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a modificar el dataset para asegurarnos de que cada característica, cada columna de X, tiene un órden de magnitud y una media diferente.\n",
    "\n",
    "Para ello, multiplica cada columna de X (excepto la primera, el bias) por un rango y súmale un valor diferente. El valor que sumemos será la media de dicha característica o columna.\n",
    "\n",
    "P. ej., $X_1 = X_1 * 10^3 + 3.1415926$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Para cada columna de X, multiplícala por un rango de valores y súmale una media diferente\n",
    "\n",
    "# Los arrays de rangos y medias tienen que ser de longitud n\n",
    "# Crea un array con los rangos de valores, p. ej.: 1e0, 1e3, 1e-2, 1e5\n",
    "rangos = [...]\n",
    "\n",
    "medias = [...]\n",
    "\n",
    "X = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar los nuevos valores de *X*, puedes ejecutar de nuevo la celda con el código para imprimirlos.\n",
    "\n",
    "Recuerda que puedes ejecutar celdas de Jupyter en un orden distinto a su posición en el documento. Los corchetes a la izquierda de las celdas marcarán el órden de ejecución, y las variables mantendrán en todo momento sus valores tras la última celda ejecutada, **¡cuidado!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación del modelo\n",
    "\n",
    "Vamos a volver a entrenar un modelo de regresión lineal. En esta ocasión, vamos a entrenarlo primero sobre el dataset original, sin normalizar, y luego reentrenarlo sobre el dataset ya normalizado, para comparar ambos modelos y procesos de entrenamiento y ver los efectos de la normalización.\n",
    "\n",
    "Para ello debes copiar las celdas o el código de ejercicios anteriores y entrenar un modelo de regresión lineal multivariable, optimizado por gradient descent, sobre el dataset original.\n",
    "\n",
    "También debes copiar las celdas que comprueban el entrenamiento del modelo, representando la función de coste vs el nº de iteraciones.\n",
    "\n",
    "No es necesario que hagas predicciones sobre estos datos ni evalues los residuos del modelo. Para compararlos, lo haremos únicamente a través del coste final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de regresión lineal y representa gráficamente su función de coste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización de los datos\n",
    "\n",
    "Vamos a normalizar los datos del dataset original.\n",
    "\n",
    "Para ello, vamos a crear una función de normalización que aplique la transformación necesaria, según la fórmula:\n",
    "\n",
    "$x = \\frac{x - \\mu_{x_j}}{\\sigma_{x_j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa una función de normalización a un rango común y con media 0\n",
    "\n",
    "def normalize(x, mu, std):\n",
    "    return [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset original usando tu función de normalización\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reentrenamiento del modelo y comparación de resultados\n",
    "\n",
    "Ahora reentrena el modelo sobre el dataset normalizado. Comprueba el coste final y la iteración en la que ha convergido.\n",
    "\n",
    "Para ello, puedes volver a las celdas de entrenar el modelo y comprobar la evolución de la función de coste y modificar la *X* utilizada por *X_norm*.\n",
    "\n",
    "En muchos casos, al ser un modelo tan simple, puede que no se aprecie ninguna mejora. En función de la capacidad de tu entorno de trabajo, prueba a utilizar un nº mayor de características y en aumentar ligeramente el término de error del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuidado con la Theta original\n",
    "\n",
    "Para el dataset original, antes de normalizarlo, se cumplía la relación $Y = X \\times \\Theta$.\n",
    "\n",
    "Sin embargo, ahora hemos modificado la *X* de dicha función.\n",
    "\n",
    "Por tanto, comprueba qué sucede si quieres volver a computar la *Y* usando la *X* normalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba si hay diferencias entre la Y original y la Y usando la X normalizada\n",
    "\n",
    "# Comprueba el valor de Y al multiplicar X_norm y Theta_verd\n",
    "Y_norm = [...]\n",
    "\n",
    "# Comprueba si hay diferencias entre Y_norm e Y\n",
    "diff = Y_norm - Y\n",
    "\n",
    "print('Diferencias entre Y_norm e Y:')\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar predicciones\n",
    "\n",
    "Del mismo modo, ¿qué sucede cuando vamos a utilizar el modelo para realizar predicciones?\n",
    "\n",
    "Genera un nuevo conjunto de datos *X_pred* siguiendo el mismo método que usaste para el dataset *X* original, incorporando el término de bias, multiplicando sus características por un rango y sumándoles valores diferentes.\n",
    "\n",
    "Del mismo modo, calcula su *Y_pred_verd* (sin término de error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo dataset de menor nº de ejemplos e igual nº de características que el dataset original\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "Y_pred_verd = np.matmul(X_pred, Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comprueba si habría alguna diferencia entre la *Y_pred_verd* y la *Y_pred* que predeciría tu modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba las diferencias entre la Y real y la Y predicha\n",
    "\n",
    "Y_pred = np.matmul(X_pred, theta)\n",
    "\n",
    "print('Diferencias entre la Y real y la Y predicha:')\n",
    "print(Y_pred_verd - Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las predicciones no son correctas, deberíamos previamente normalizar la nueva *X_pred*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza la X_pred\n",
    "\n",
    "X_pred[...] = normalize(X_pred[...], mu, std)\n",
    "\n",
    "print(X_pred)\n",
    "print(X_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasión no hemos generado una nueva variable diferente al normalizar, sino que sigue siendo la variable *X_pred*.\n",
    "\n",
    "Así puedes reejecutar las celdas anteriores para, ahora que *X_pred* está normalizada, comprobar si hay alguna diferencia entre la *Y* real y la *Y* predicha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, recuerda siempre:\n",
    "- La *theta* calculada al entrenar el modelo será relativa siempre al dataset normalizado, y no se podrá usar para el dataset original, ya que a igual *Y* y distinta *X*, *Theta* debe cambiar.\n",
    "- Para hacer predicciones sobre nuevos ejemplos, antes tenemos que normalizarlos también, usando los mismos valores de medias y desviaciones típicas que usamos originalmente para entrenar el modelo."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
