{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal: Ejemplo sintético con Scikit-learn\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "\n",
    "- Resolver un modelo de regresión lineal multivariable usando Scikit-learn.\n",
    "\n",
    "Una vez desarrollada una implementación a mano del algoritmo de regresión lineal multivariable sobre Numpy exclusivamente, hemos podido ver en profundidad los pasos a seguir, cómo funciona el algoritmo matemático interno, y cómo le afectan todos los hiper-parámetros.\n",
    "\n",
    "Habiendo entendido bien entonces cómo funcionan dichos modelos de ML, vamos a ver cómo utilizarlos con las funciones del framework de ML de Scikit-learn.\n",
    "\n",
    "En este ejercicio tendrás una plantilla en blanco con los pasos que hemos seguido en ejercicios anteriores, que tendrás que completar con tu código siguiendo dichos pasos, pero esta vez usando algunas funciones de Scikit-learn.\n",
    "\n",
    "En cada celda te sugeriremos una función de Scikit-learn que puedes usar. No te daremos más información aquí sobre ella, porque queremos que la busques por ti mismo en la documentación: su funcionamiento, algoritmos que implementa (algunos serán ligeramente diferentes a los que hemos visto en el curso, no te preocupes puesto que lo importante es la base), argumentos, ejemplos, etc.\n",
    "\n",
    "Parece de perogrullo, pero seguro que estarás de acuerdo con nosotros que la habilidad de saber encontrar la información relevante en cada momento en la documentación es muy importante, y muchas veces nos puede costar algo más de lo debido :).\n",
    "\n",
    "Aprovecha también para bucear más en la documentación y descubrir aspectos interesantes del framework. Seguiremos trabajando con él en ejercicios posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético para regresión lineal\n",
    "\n",
    "- Añádele un término de bias y de error modificable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crea un dataset sintético para regresión lineal con Scikit-learn\n",
    "# Puedes usar la función sklearn.datasets.make_regression()\n",
    "# Recuerda usar siempre un inicio de estado aleatorio determinado para mantener la reproducibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "- Reordenarlos aleatoriamente.\n",
    "- Normalizarlos.\n",
    "- Dividirlos en subsets de entrenamiento y test.\n",
    "\n",
    "*Nota*: ¿Por qué esta vez usamos 2 subsets de entrenamiento y test únicamente, sin CV? Porque usaremos *k-fold* para nuestra validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente\n",
    "# Puedes usar la función sklearn.utils.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los ejemplos\n",
    "# Puedes usar la clase sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Este escalado es equivalente al normalizado básico que hemos visto durante el curso. Otra normalización más conveniente en modelos más avanzados pero más compleja de entender sería la implementada en *sklearn.preprocessing.normalize*.\n",
    "\n",
    "Puedes encontrar todos las clases y funciones de preprocesamiento disponibles aquí: [Sklearn docs: 6.3. Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "\n",
    "Y una comparativa gráfica: [Compare the effect of different scalers on data with outliers](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset en los subsets de entrenamiento y test\n",
    "# Puedes usar la función sklearn.model_selection.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial\n",
    "\n",
    "- Entrenar un modelo inicial sobre el subset de entrenamiento sin regularización.\n",
    "- Comprueba la idoneidad del modelo.\n",
    "- Comprueba si existe desviación o sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar un modelo simple de regresión lineal multivariable, puedes usar la clase [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "\n",
    "Puedes consultar un ejemplo completo de entrenamiento: [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de regresión lineal más simple sobre el subset de entrenamiento sin regularización\n",
    "# Ajusta el término de intercept/bias y no normalices las características, puesto que las hemos normalizado ya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba la idoneidad del modelo aplicado a este dataset. Para ello puedes usar:\n",
    "- El coeficiente de determinación R^2 del método [LinearRegression.score()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score)\n",
    "- La función [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)\n",
    "- La función [sklearn.metrics.r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)\n",
    "\n",
    "Prueba los 3 métodos para conocerlos mejor y ver sus posibles diferencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba la idoneidad del modelo evaluándolo sobre el set de test\n",
    "# Comprueba las 3 métricas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar si pudiera existir desviación o sobreajuste, podemos calcular p. ej. el error cuadrado medio sobre las predicciones del subset de entrenamiento y sobre las del de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba si la evaluación sobre ambos subsets es similar con el mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallar la regularización óptima por validación cruzada\n",
    "\n",
    "- Entrena un modelo por cada valor de regularización a considerar.\n",
    "- Entrénalos y evalúalos sobre una divisón del subset de entrenamiento por K-fold.\n",
    "- Escoge el modelo y regularización óptimos.\n",
    "\n",
    "Ahora vamos a usar un algoritmo de regresión lineal más complejo, la clase [sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) que nos permite establecer un parámetro de regularización L2.\n",
    "\n",
    "En esta función, dicho parámetro se denomina *alpha*, aunque no debemos confundirlo con el ratio de aprendizaje.\n",
    "\n",
    "La regularización L2 es ligeramente diferente al parámetro *lambda* que hemos visto durante el curso, aunque comparten una base común. Es la regularización que implementan la mayoría de algoritmos de Scikit-learn, aunque por si complejidad no la estudiaremos aquí. ¡Aunque, por supuesto, puedes investigar más sobre ella si quieres!\n",
    "\n",
    "Considera unos parámetros de regularización L2 en el rango logarítmico [0, 0.1]: 0.1, 0.01, 0.001, 0.0001, etc.\n",
    "\n",
    "Puedes guiarte por este enlace: [K-fold](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo diferente por cada alpha sobre un fold de K-fold diferente\n",
    "\n",
    "# Usa una función de Numpy para crear un espacio logarítmico de 5 valores entre [0, 0.1]\n",
    "alphas = [...]\n",
    "\n",
    "# Crea 5 splits de K-fold\n",
    "kf = [...]\n",
    "\n",
    "# Itera sobre los 5 splits para tus modelos y evalúalos en el subset de CV generado\n",
    "linear_models = []\n",
    "best_model = None\n",
    "for train, cv in kf.split(X):\n",
    "    # Entrena un modelo sobre el subset train\n",
    "    # Recuerda establecer el parámetro alpha correspondiente, ajustar el bias y no normalizar\n",
    "    # Evalúalo sobre el subset cv usando su método score()\n",
    "    # Guarda el modelo con el mejor score en la variable best_model y muestra el alpha del mejor modelo\n",
    "    alpha = [...]\n",
    "    print('Regularización L2 usada:', alpha)\n",
    "    \n",
    "    linear_models[...] = [...]\n",
    "    \n",
    "    # Si el modelo es mejor que el mejor modelo hasta ahora...\n",
    "    best_model = [...]\n",
    "    print('Regularización L2 del mejor modelo hasta ahora:', alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo finalmente sobre el subset de test\n",
    "\n",
    "- Muestra los coeficientes e intercept del mejor modelo.\n",
    "- Evalúa el mejor modelo sobre el subset de test inicial.\n",
    "- Calcula los resíduos sobre el subset de test y represéntalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el mejor modelo sobre el subset de test inicial\n",
    "\n",
    "# Muestra los coeficientes e intercept del mejor modelo entrenado\n",
    "print('Coeficientes de intercept del modelo entrenado')\n",
    "print()    # Muestra el intercept como el primer coeficiente\n",
    "\n",
    "# Realiza las predicciones sobre el subset de test\n",
    "y_test_pred = [...]\n",
    "\n",
    "# Calcula las métricas de evaluación del modelo: error cuadrático medio y coeficiente de determinación\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "\n",
    "print('Error cuadrático medio: %.2f' % mse)\n",
    "print('Coeficiente de determinación: %.2f' % r2_score)\n",
    "\n",
    "# Calcula los resíduos sobre el subset de test\n",
    "res = [...]\n",
    "\n",
    "# Represéntalos gráficamente\n",
    "plt.figure(1)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "- Genera un nuevo ejemplo siguiendo el mismo patrón del dataset original.\n",
    "- Normaliza sus características.\n",
    "- Genera una predicción para dicho ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Realiza predicciones sobre un nuevo ejemplo creado manualmente\n",
    "\n",
    "# Crea el nuevo ejemplo\n",
    "X_pred = [...]\n",
    "\n",
    "# Normaliza sus características\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo\n",
    "y_pred = [...]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
