{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal: Validación cruzada y evaluación final\n",
    "\n",
    "Finalmente, vamos a entrenar un modelo de regresión lineal por completo, aplicando preprocesado de datos, comprobando el modelo por validación cruzada, evaluándolo sobre un subset de testing y, finalmente, realizando predicciones con el mismo.\n",
    "\n",
    "Éste es pues un ejemplo completo de cómo entrenar un modelo de regresión lineal multivariable.\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético para regresión lineal multivariable\n",
    "- Preprocesar los datos\n",
    "- Entrenar el modelo sobre el subset de entrenamiento y comprobar su idoneidad\n",
    "- Hallar el hiper-parámetro *lambda* óptimo sobre el subset de validación cruzada o CV\n",
    "- Evaluar el modelo sobre el subset de test\n",
    "- Realizar prediccioes sobre nuevos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético para regresión lineal\n",
    "\n",
    "Vamos a comenzar, como siempre, creando un dataset sintético para este ejercicio.\n",
    "\n",
    "Crea uno de forma manual con un término de error modificable, sin olvidar su término de bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético manualmente, con término de bias y término de error\n",
    "\n",
    "m = 1000\n",
    "n = 3\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_verd = [...]\n",
    "\n",
    "error = 0.2\n",
    "\n",
    "Y = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Vamos a preprocesar los datos completamente, para dejarlos listos.\n",
    "\n",
    "Esta vez, vamos a seguir los siguientes pasos para preprocesar los datos:\n",
    "- Reordenarlos aleatoriamente.\n",
    "- Normalizarlos.\n",
    "- Dividirlos en subsets de entrenamiento, validación cruzada y test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordenar el dataset aleatoriamente\n",
    "\n",
    "En esta ocasión vamos a usar un dataset sintético creado en base a datos aleatorios. Por tanto, no sería necesario reordenarlos, puesto que al ser aleatorios ya vienen desorganizados por defecto.\n",
    "\n",
    "Sin embargo, habitualmente nos podemos encontrar con datasets reales cuyos datos tienen un cierto orden, patrón, que puede confundir nuestro entrenamiento.\n",
    "\n",
    "Por tanto, siempre antes de empezar a tratar los datos, lo primero que hacemos es reordenarlos aleatoriamente, muy especialmente antes de dividirlos en los subsets de entrenamiento, CV y test.\n",
    "\n",
    "*Nota*: Muy importante, recuerda siempre reordenar *X* e *Y* con el mismo orden, para que cada ejemplo tenga asignado el mismo resultado antes y después de reordenarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente el dataset\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Si lo prefieres, puedes usar la función de conveniencia de sklearn.utils.shuffle\n",
    "# Usa un estado aleatorio inicial de 42, para mantener la reproducibilidad\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba que *X* e *Y* tienen las dimensiones correctas y un orden diferente al anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar el dataset\n",
    "\n",
    "Una vez reordenados aleatoriamente los datos, vamos a proceder a normalizar el dataset de ejemplos *X*.\n",
    "\n",
    "Para ello, copia las celdas de código de ejercicios anteriores para normalizarlo.\n",
    "\n",
    "*Nota*: En ejercicios pasados usábamos 2 celdas de código diferentes, una para definir la función de normalización y otra para normalizar el dataset. Puedes combinar ambas celdas en una para guardar dicho preprocesamiento en una celda reutilizable en el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "def normalize(x, mu, std):\n",
    "    \"\"\" Normaliza un dataset con ejemplos X\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los ejemplos, sin término de bias\n",
    "    mu -- vector 1D de Numpy con la media de cada característica/columna\n",
    "    std -- vector 1D de Numpy con la desviación típica de cada característica/columna\n",
    "    \n",
    "    Devuelve:\n",
    "    x_norm -- array 2D de Numpy con los ejemplos, con sus características normalizadas\n",
    "    \"\"\"\n",
    "    return [...]\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Hay quien prefiere calcular la media *mu* y la desviación típica *std* de cada característica/columna de *X* en la misma función de normalización si no se incluyen como argumentos (que serían opcionales pues), devolviendo los 3 valores, puesto que para hacer predicciones necesitamos normalizar los datos con la misma *mu* y *std* original.\n",
    "\n",
    "Si lo prefieres, puedes modificar tu implementación de la función para hacerlo así."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento, CV y test\n",
    "\n",
    "Por último, vamos a dividir el dataset en los 3 subsets a utilizar.\n",
    "\n",
    "Para ello, vamos a usar un ratio de 60%/20%/20%, ya que partimos de 1000 ejemplos.\n",
    "Como decíamos, para un nº de ejemplos diferente, podemos modificar el ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 3 subsets según los ratios indicados\n",
    "\n",
    "ratios = [60,20,20]\n",
    "print('Ratios:\\n', ratios, ratios[0] + ratios[1] + ratios[2])\n",
    "\n",
    "r = [0,0]\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r[0] = [...]\n",
    "r[1] = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_cv, X_test = [...]\n",
    "Y_train, Y_cv, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_cv.shape)\n",
    "print(Y_cv.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial sobre el subset de entrenamiento\n",
    "\n",
    "Antes de comenzar a optimizar el hiper-parámetro *lambda*, vamos a entrenar un modelo inicial sin regularización sobre el subset de entrenamiento, para comprobar su rendimiento e idoneidad, y estar seguros que tiene sentido entrenar un modelo de ML de regresión lineal multivariable sobre dicho dataset, ya que las características podrían no ser las adecuadas, haber una baja relación entre ellas, no seguir una relación lineal, etc.\n",
    "\n",
    "Para ello, vamos a seguir los siguientes pasos:\n",
    "- Entrenar un modelo inicial, sin regularización, con *lambda* a 0.\n",
    "- Representar el histórico de la función de coste para comprobar su evolución.\n",
    "- Reentrenar el modelo si es necesario, p. ej. variando el ratio de aprendizaje *alpha*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copia las celdas de ejercicios anteriores donde implementabas las funciones de coste y gradient descent regularizadas, y copia la celda donde entrenabas el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia las celdas con las funciones de coste y gradient descent regularizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda donde entrenamos el modelo\n",
    "# Entrena tu modelo sobre el subset de entrenamiento sin regularizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma que hacíamos antes, comprueba el entrenamiento del modelo, representando gráficamente la evolución de la función de coste según el nº de iteraciones, copiando la celda de código correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones\n",
    "\n",
    "plt.figure(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como decíamos antes, revisa el entrenamiento de tu modelo y modifica algún parámetro si es necesario para reentrenarlo, buscando que tenga un buen rendimiento: el ratio de aprendizaje, el punto de convergencia, el nº máx. de iteraciones, etc., excepto el parámetro de regularización *lambda*, que debe estar a 0.\n",
    "\n",
    "*Nota*: Este punto es importante, puesto que por lo general, estos hiper-parámetros serán los mismos que utilizaremos para lo que resta de la optimización del modelo, por lo que ahora es el momento de encontrar los valores idóneos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar si existe desviación o sobreajuste, *bias* o *varianza*\n",
    "\n",
    "Hay un test que podemos hacer rápidamente para comprobar si nuestro modelo inicial sufre claramente de desviación, de varianza, o tiene un funcionamiento más o menos aceptable.\n",
    "\n",
    "Vamos a representar gráficamente la evolución de la función de coste de 2 modelos, uno entrenado sobre los primeros *n* ejemplos del subset de entrenamiento y otro entrenado sobre los primeros *n* ejemplos del subset de validación cruzada.\n",
    "\n",
    "Puesto que el subset de entrenamiento y el subset de validación cruzada no tienen el mismo tamaño, usa únicamente el mismo nº de ejemplos para este subset que ejemplos totales tenga el de CV.\n",
    "\n",
    "Para ello entrena 2 modelos en igualdad de condiciones, copiando de nuevo las celdas de código correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Establece una theta_ini e hiper-parámetros comunes a ambos modelos, para entrenarlos en igualdad de \n",
    "# condiciones\n",
    "\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "lambda_ = 0.\n",
    "e = 1e-3\n",
    "iter_ = 1e3\n",
    "\n",
    "print('Hiper-arámetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo sin regularización sobre los n primeros valores de X_train, donde n es el nº de\n",
    "# ejemplos disponibles en X_cv\n",
    "# Usa j_hist_train y theta_train como nombres de variables para distinguirlos del otro modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Comprueba que *theta_ini* no se ha modificado, o modifica tu código para que ambos modelos usen la misma *theta_ini*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Del mismo modo, entrena un modelo sin regularización sobre X_cv con los mismos parámetros\n",
    "# Recuerda usar j_hist_cv y theta_cv como nobmres de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora representa gráficamente ambas evoluciones sobre la misma gráfica, con colores diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa en una gráfica de líneas ambas evoluciones para compararlas\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "# Usa colores diferentes para ambas series, e indica una leyenda para distinguirlos\n",
    "plt.plot()\n",
    "plt.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un dataset sintético aleatorio es difícil que se diera un caso u otro, pero de esta forma podríamos apreciar dichos problemas de la siguiente forma:\n",
    "\n",
    "- Si el coste final en ambos subsets es alto, puede haber un problema de desviación o *bias*.\n",
    "- Si el coste final en ambos subsets es muy diferente entre sí, puede haber un problema de sobreajuste o *varianza*\n",
    "\n",
    "Recordamos qué significaban ambos:\n",
    "- La desviación se produce cuando el modelo no puede ajustar suficientemente bien la curva del dataset, sea porque no son las características correctas (o faltarían otras), sea porque los datos tienen demasiado error, o sea porque el modelo sigue una relación distinta o sea demasiado simple.\n",
    "- El sobreajuste se produce cuando el modelo ajusta muy bien la curva del dataset, demasiado bien, demasiado ajustada a los ejemplos sobre los que se ha entrenado, y cuando tiene que predecir sobre nuevos resultados no lo hace correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar la idoneidad del modelo\n",
    "\n",
    "Como decíamos, otra razón para entrenar un modelo inicial es comprobar si tiene sentido entrenar un modelo de regresión lineal multivariable sobre dicho dataset.\n",
    "\n",
    "Si vemos que el modelo sufre de sobreajuste, siempre podemos corregirla con la regularización. Sin embargo, si vemos que sufre de una alta desviación, i.e. que el coste final es muy alto, puede que nuestro tipo de modelo o las características escogidas no sean idóneas para este problema.\n",
    "\n",
    "En este caso, hemos comprobado que el error es suficientemente bajo para que resulte prometedor continuar entrenando dicho modelo de regresión lineal multivariable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallar el hiper-parámetro *lambda* óptimo sobre el subset de validación cruzada\n",
    "\n",
    "Ahora, para conseguir hallar la *lambda* óptima, vamos a entrenar un modelo diferente por cada valor de *lambda* a considerar, sobre el subset de entrenamiento, y comprobar su precisión sobre el subset de validación cruzada.\n",
    "\n",
    "Vamos a representar gráficamente el error o coste final de cada modelo vs el valor de *lambda* usado, para ver qué modelo tiene un error o coste menor en el subset de validación cruzada.\n",
    "\n",
    "De esta forma, entrenamos todos los modelos sobre el mismo subset y en igualdad de condiciones (excepto *lambda*), y los evaluamos en un subset de datos que no han visto previamente, que no hemos usado para entrenarlos.\n",
    "\n",
    "El subset de CV, por tanto, no se usa para entrenar el modelo, sino sólo para evaluar el valor de *lambda* óptimo. Excepto, como hemos hecho en el punto anterior, para hacer una evaluación inicial rápida sobre la posible aparición de sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo por cada valor de lambda diferente sobre X_train y evalúalo sobre X_cv\n",
    "\n",
    "lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "\n",
    "# Completa el código para entrenar un modelo diferente para cada valor de lambda sobre X_train\n",
    "# Almacena su theta y error/coste final\n",
    "# Posteriormente, evalúa su coste total en el subset de CV\n",
    "\n",
    "# Almacena dicha información en los siguientes arrays, del mismo tamaño que lambdas\n",
    "j_train = [...]\n",
    "j_cv = [...]\n",
    "theta_cv = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenados todos los modelos, representa en una gráfica de líneas su coste final sobre el subset de entrenamiento y el coste final sobre el de CV vs el valor de *lambda* utilizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el error final para cada valor de lambda\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "# Completa con tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez representados dichos errores finales, podríamos elegir manualmente el modelo con el valor de *lambda* óptimo, o podemos hacerlo de forma automatizada con código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escoge el modelo y el valor de lambda óptimos, con el menor error sobre el subset de CV\n",
    "\n",
    "# Itera sobre todas las combinaciones de theta y lambda y escoge las de menor coste en el subset de CV\n",
    "\n",
    "j_final = [...]\n",
    "theta_final = [...]\n",
    "lambda_final = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez implementados todos los pasos anteriores, tenemos nuestro modelo entrenado y sus hiper-parámetros optimizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo finalmente sobre el subset de test\n",
    "\n",
    "Finalmente, hemos encontrado nuestros coeficientes *theta* e hiper-parámetro *lambda* óptimos, por lo que ya disponemos de un modelo entrenado y listo para ser usado.\n",
    "\n",
    "Sin embargo, aunque hemos calculado su error o coste final sobre el subset de CV, hemos usado dicho subset para escoger el modelo, para terminar de \"entrenarlo\", para actuar sobre el modelo. Por tanto, no hemos comprobado todavía cómo funcionará este modelo sobre datos que no ha visto nunca antes.\n",
    "\n",
    "Por ello, vamos a evaluarlo finalmente sobre el subset de test, sobre un subset que no hemos utilizado aún, ni para entrenar el modelo, ni para escoger sus hiper-parámetros. Un subset separado que el entrenamiento del modelo no ha visto aún.\n",
    "\n",
    "Para ello, vamos a calcular el error o coste total sobre el subset de test y comprobar gráficamente los resíduos del modelo sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error del modelo sobre el subset de test usando la función de coste con las correspondientes\n",
    "# theta y lambda\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones del modelo sobre el subset de test, calcula los resíduos y represéntalos\n",
    "\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma podemos hacernos una idea más real sobre la precisión de nuestro modelo y cómo se comportará con nuevos ejemplos en el futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestro modelo ya entrenado, optimizado y evaluado, lo único que nos queda es ponerlo en funcionamiento realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias y error aleatorio\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas originales\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo\n",
    "Y_pred = [...]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
