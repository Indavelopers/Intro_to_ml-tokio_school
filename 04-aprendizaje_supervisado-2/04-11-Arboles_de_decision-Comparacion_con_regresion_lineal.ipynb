{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión: Comparación de árboles de regresión con regresión lineal\n",
    "\n",
    "## ¿Qué vamos a ver?\n",
    "- Comparar la precisión y el comportamiento de los árboles de decisión frente a la regresión lineal tradicional\n",
    "\n",
    "En algunas ocasiones se estima que los árboles de regresión pueden no tener tanta precisión y caer en más sobreajuste frente a la regresión lineal tradicional, especialmente con un alto nº de características.\n",
    "\n",
    "En este ejercicio, vamos a seguir los pasos habituales para entrenar 2 modelos de regresión lineal: un árbol de decisión y un Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar un dataset sintético\n",
    "\n",
    "Genera un dataset sintético con un término de error algo acusado y bastantes características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético para regresión lineal con un término de error\n",
    "\n",
    "m = 1000\n",
    "n = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tu entorno de trabajo no tiene suficientes recursos, reduce el nº de características a 9, p. ej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "- Reordena los datos aleatoriamente.\n",
    "- Normalízalos.\n",
    "- Divídelos en subsets de entrenamiento y test.\n",
    "\n",
    "*Nota*: De nuevo usaremos K-fold para la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset en subset de entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizar los modelos por validación cruzada\n",
    "\n",
    "- Entrena un modelo por cada valor de regularización o profundidad máx. a considerar.\n",
    "- Entrénalos y evalúalos sobre una divisón del subset de entrenamiento por K-fold.\n",
    "- Escoge el modelo y su regularización óptimos.\n",
    "\n",
    "Considera unos parámetros similares a los de ejercicios pasados:\n",
    "- Profundidad máxima en el rango [1, 8]\n",
    "- Parámetro de regularización L2 *alpha* en el rango logarítmico [0, 0.1]: 0.1, 0.01, 0.001, 0.0001, etc.\n",
    "\n",
    "Puedes copiar las celdas de ejercicios anteriores y modificarlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo diferente sobre un fold de K-fold diferente para árbol de regresión y Lasso\n",
    "\n",
    "# Itera sobre los splits de K-fold necesarios, entrena tus modelos y evalúalos sobre el subset de CV\n",
    "# Puede que los árboles de decisión y los modelos lineales de Lasso requieran un nº diferente de splits\n",
    "mejor_tree = [...]\n",
    "mejor_lasso = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar los mejores modelos de árbol de decisión y Lasso sobre el subset de test.\n",
    "\n",
    "Para ello, calcula sus métricas de MSE y R^2 score y representa gráficamente las predicciones del modelo vs el subset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con MSE y R^2 sobre el subset de test para mejor árbol y Lasso\n",
    "\n",
    "y_train_test = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Error cuadrático medio: %.2f', mse)\n",
    "print('Coeficiente de determinación: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, comprueba su posible desviación o sobreajuste y precisión final representando gráficamente los residuos de ambos modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente los residuos de ambos modelos\n",
    "\n",
    "residuos_tree = [...]\n",
    "residuos_lasso = [...]\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representa en un gráfico de puntos el subset de test\n",
    "plt.scatter([...])\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Hay diferencias significativas entre ambos modelos? ¿Qué ocurre si variamos el error o el nº de características del dataset original, cómo responden ambos tipos de modelos?*\n",
    "\n",
    "Para el caso del árbol de regresión, tal vez no hayamos hecho la comparativa más justa, puesto que quedan otros hiper-parámetros que podemos modificar: [sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "## *Bonus*: Optimización de todos los hiper-parámetros del árbol de decisión\n",
    "\n",
    "*¿Te atreves a usar [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) no sólo para optimizar max_depth, sino para todos los hiper-parámetros del árbol de regresión?*\n",
    "\n",
    "En la página de la documentación de GridSearchCV tienes un ejemplo que puedes tomar como referencia."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
