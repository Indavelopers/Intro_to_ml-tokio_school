{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de anomalías: Comparación con clasificación\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "\n",
    "- Crear un dataset sintético para detección de anomalías con casos normales y anómalos.\n",
    "- Comparar la resolución del dataset con los métodos de detección de anomalías por baja probabilidad y clasificación por SVM.\n",
    "- Evaluar ambos métodos y representar gráficamente sus resultados.\n",
    "\n",
    "Los métodos de detección de anomalías por la covarianza de la distribución gaussiana y la baja probabilidad de un evento (el método que hemos usado en el ejercicio anterior) y por clasificación son bastante similares, especialmente si la clasificación la hacemos con el SVM de kernel gaussiano, ya que ambos tratan de modelizar la misma distribución gaussiana sobre los datos.\n",
    "\n",
    "Sus principales diferencias se aprecian sólo en algunas circunstancias, como p. ej.:\n",
    "- La distribución de los ejemplos normales no es gaussiana/normal, o tiene múltiples centroides que no hemos detectado de antemano por agrupación, p. ej., y la clasificación no la hacemos por SVM gaussiano.\n",
    "- En dataset de un número alto de dimensiones, mantener la distribución normal de los datos es más difícil.\n",
    "- La clasificación, al ser un método de aprendizaje supervisado, puede necesitar un porcentaje de datos anómalos superior al del aprendizaje reforzado.\n",
    "\n",
    "En este ejercicio vamos a combinar ambos métodos, que ya has resuelto en ejercicios anteriores, para analizar sus resultados y diferencias.\n",
    "\n",
    "Sigue las siguientes instrucciones para resolver el mismo dataset por covarianza de la distribución gaussiana y por SVM con kernel gaussiano, copiando las celdas de código de ejercicios anteriores siempre que sea posible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Usa esta celda para importar todas las librerías necesarias\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del dataset original\n",
    "\n",
    "Vamos a crear un dataset sintético siguiendo los mismos pasos que en el ejercicio de detección de anomalías anterior. Sin embargo, luego crearemos 2 conjuntos de 3 subconjuntos de datos de entrenamiento, validación y test diferentes, ya que para la detección por covarianza de la distribución gaussiana no asignábamos valores anómalos al subset de entrenamiento y para la clasificación por SVM sí lo necesitamos hacer.\n",
    "\n",
    "Los pasos que vamos a dar pues serán:\n",
    "1. Crear un dataset de datos normales y otro de datos anómalos.\n",
    "1. Normalizar dichos datos.\n",
    "1. Crear un conjunto de subsets de entrenamiento, validación y test para resolver por covarianza de distribución gaussiana, sin datos anómalos en el subset de entrenamiento.\n",
    "1. Crear un conjunto de subsets de entrenamiento, validación y test para resolver por SVM con kernel gaussiano, con datos anómalos en todos los subsets.\n",
    "1. Reordenar los datos aleatoriamente de los 2 conjuntos de subsets.\n",
    "1. Representar gráficamente los datos de los 2 conjuntos de subsets.\n",
    "\n",
    "Por tanto, completa las siguientes celdas de código, copiando tu código de ejercicios anteriores siempre que sea posible. Al final debes haber generado, normalizado, dividido y reordenado las matrices *X_cdg_train, X_cdg_cv, X_cdg_test, X_svm_train, X_svm_cv, X_svm_test* y sus *Y* correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera dos datasets sintéticos independientes con datos normales y anómalos\n",
    "\n",
    "m = 500\n",
    "n = 2\n",
    "ratio_anomalos = 0.25    # Porcentaje de datos anómalos vs datos normales, modificable\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los datos de ambos datasets con los mismos parámetros de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide los datasets en los subsets de entrenamiento, validación y test para covarianza de dist. gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide los datasets en los subsets de entrenamiento, validación y test para clasificación por SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente los 2 conjuntos de subsets de entrenamiento, validación y test individualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa los 3 subsets en una gráfica 2D para covarianza de distribución gaussiana y clasificación por SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolución por deteccion de anomalías por covarianza de la distribución normal\n",
    "\n",
    "Para resolver el dataset por covarianza de la distribución normal, sigue los pasos del ejercicio anterior, copiando las celdas correspondientes en las siguientes celdas, y teniendo cuidado de utilizar los subsets adecuados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modeliza la distribución gaussiana y obtén mu y Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa múltiples valores de epsilon y halla el más óptimo para clasificar datos como normales o anómalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula la F1-score del modelo sobre el subset de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolución por clasificación por SVM\n",
    "\n",
    "Del mismo modo, sigue los pasos del ejercicio sobre SVM anterior para clasificar los datos en normales y anómalos por SVM, copiando las celdas correspondientes en las siguientes celdas siempre que sea posible, y teniendo cuidado de utilizar los subsets adecuados.\n",
    "\n",
    "Utiliza un kernel RBF con la función de Scikit-learn [OneClassSVM](https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html) y *ratio_anomalos* como parámetro *nu*. Para regularizar el modelo, optimiza *gamma* con [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de OneClassSVM y optimiza gamma en el subset de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula la F1-score del modelo sobre el subset de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de los resultados de ambos métodos\n",
    "\n",
    "Ahora compara ambos métodos, mostrando su F1-score y representando gráficamente sus resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Muestra los resultados de la F1-score de ambos modelos\n",
    "\n",
    "print('F1-score de la covarianza de la distribución gaussiana:')\n",
    "print()\n",
    "print('F1-score de la clasificación por SVM:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representa los resultados de ambos modelos. Como los subsets de test son diferentes en ambos casos, en esta ocasión calcula los errores y aciertos sobre los datos de los 3 subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa errores y aciertos junto a la distribución y el corte de epsilon\n",
    "# para la covarianza de la distribución gaussiana\n",
    "\n",
    "# Asigna z = 1. para acierto y z = 0. para fallo\n",
    "# Acierto: Y_test == Y_test_pred\n",
    "z_cdg = [...]\n",
    "\n",
    "# Representa la gráfica\n",
    "# Utiliza colores diferentes para los datos que ha acertado y los que ha fallado\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa errores y aciertos en el subset de test junto a la distribución y el corte de epsilon\n",
    "# para la clasificación por SVM\n",
    "\n",
    "# Asigna z = 1. para acierto y z = 0. para fallo\n",
    "# Acierto: Y_test == Y_test_pred\n",
    "z_svm = [...]\n",
    "\n",
    "# Representa la gráfica\n",
    "# Utiliza colores diferentes para los datos que ha acertado y los que ha fallado\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Qué conclusiones puedes sacar? ¿Qué diferencias hay entre ambos métodos?*\n",
    "\n",
    "*BONUS: ¿Se te ocurre cómo modificar los datsets iniciales buscando que ambos métodos obtengan resultados diferentes?*"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
