{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística: Dataset Iris\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Descargar y analizar el dataset Iris.\n",
    "- Preprocesar el dataset.\n",
    "- Entrenar un modelo de clasificación sobre el mismo.\n",
    "- Optimizar nuestro modelo por validación cruzada.\n",
    "\n",
    "El dataset Iris es uno de los más conocidos y utilizados en ML. Lo usamos habitualmente como ejemplo para explicar algoritmos de modelos, y también se usa ampliamente para comparar varios modelos entre sí, en función de su precisión en el mismo.\n",
    "\n",
    "Puedes conocer más sobre este dataset en la Wikipedia: [Conjuntos de datos flor iris](https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris)\n",
    "\n",
    "Puedes encontrar este modelo en Scikit-learn como [dataset de ejemplo](https://scikit-learn.org/stable/datasets/index.html#iris-dataset) y cargarlo con la función [sklearn.datasets.load_iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html).\n",
    "\n",
    "En este ejercicio vas a seguir los mismos pasos del último ejercicio para resolver un modelo de clasificación de 3 clases, en este caso sobre un dataset real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el dataset Iris\n",
    "\n",
    "Carga el dataset y analiza algunos de los ejemplos para conocer más sobre él.\n",
    "\n",
    "Puede que te sea interesante representarlos gráficamente como en este ejercicio: [The Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Carga el dataset Iris como arrays X e Y\n",
    "# Comprueba en qué formato está codificado Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Preprocesa los datos siguiendo los pasos habituales:\n",
    "- Reordénalos aleatoriamente.\n",
    "- Normalízalos, sólo si es necesario.\n",
    "- Divídelos en subsets de entrenamiento, CV y test.\n",
    "\n",
    "*Nota*: Cuidado a la hora de dividirlos en subsets, *¿cuántos ejemplos tiene el dataset original?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los datos si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divídelos en subsets de entrenamiento, CV y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementa la función de activación sigmoide, la función de coste regularizada y la función de entrenamiento por gradient descent regularizado\n",
    "\n",
    "Copia el código de ejercicios anteriores para implementar dichas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la función sigmoide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa las funciones de coste y gradient descent regularizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrena un modelo inicial para cada clase\n",
    "\n",
    "Para asegurarte de que tu implementación funciona bien con el formato del dataset, entrena un modelo inicial simple para cada clase sin regularización.\n",
    "\n",
    "Comprueba si tu implementación trabaja bien con el formato del dataset. Si es necesario, modifica el dataset para que puedas usarlo con tu código.\n",
    "\n",
    "Modifica los parámetros de entrenamiento y reentrénalos si es necesario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena tus modelos sobre el subset de entrenamiento sin regularizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halla el hiper-parámetro *lambda* óptimo por CV\n",
    "\n",
    "Una vez entrenado el modelo inicial, y viendo su rendimiento, vamos a entrenar un modelo por cada una de las 3 clases, con varios valores de *lambda*, al igual que en ejercicios pasados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo por cada valor de lambda diferente para cada una de las clases, y evalúalo sobre X_cv\n",
    "# Los valores de lambda que considerábamos anteriormente eran:\n",
    "# lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "# Si lo prefieres, modifica el nº de valores lambda para no entrenar tantos modelos y que tarde tanto tiempo\n",
    "lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el error final para cada valor de lambda con una gráfica por clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escoge el mejor modelo para cada clase\n",
    "\n",
    "Copia las celdas de código de ejercicios anteriores y modifícalas si es necesario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escoge los modelos y valores de lambda óptimos para cada clase sobre el subset de CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalúa los modelos sobre el subset de test\n",
    "\n",
    "Una vez entrenados los modelos, evalúalos sobre el subset de test.\n",
    "\n",
    "En este caso, vamos a hacer una evaluación final más completa. En lugar de evaluar los 3 modelos por separado, sólo con la *Y* que vería cada modelo, haz predicciones sobre el subset de test de la misma forma que hiciste en el último apartado del ejercicio anterior (\"Realizar predicciones sobre nuevos ejemplos\"): esto es, para todo el subset de test, realiza una predicción para cada modelo de cada clase y escoge el de mayor resultado.\n",
    "\n",
    "Además, añade una nueva modificación: a la hora de escoger la clase con mayor valor tras el sigmoide, sólo escoge clases cuyo sigmoide sea >= 0.5, puesto que en ocasiones los 3 modelos pueden predecir valores de 0.1, 0.2, 0.25, etc., que realmente están prediciendo que el ejemplo no entra dentro de ninguna de sus 3 clases.\n",
    "\n",
    "Con dichas predicciones, calcula los resíduos y represéntalos gráficamente.\n",
    "\n",
    "De esta forma estamos evaluando nuestro modelo de cara a un entorno mucho más próximo a la realidad, usando también para ello un dataset real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error del modelo con los resíduos sobre el subset de test y represéntalos gráficamente"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
