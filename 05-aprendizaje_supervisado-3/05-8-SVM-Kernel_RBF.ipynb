{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: Kernel RBF\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Generar un dataset sintético de 2 clases (binario).\n",
    "- Preprocesar el dataset.\n",
    "- Entrenar un modelo de clasificación por SVM sobre el mismo.\n",
    "- Comprobar su idoneidad.\n",
    "- Optimizar los hiper-parámetros de nuestro modelo por validación cruzada.\n",
    "- Evaluar nuestro modelo.\n",
    "\n",
    "Del mismo modo que habíamos hecho para la clasificación por regresión logística usando Scikit-learn, ahora vamos a usar este framework para resolver problemas de clasificación por SVM.\n",
    "\n",
    "En concreto, vamos a usar su clasificador SVC con el kernel RBF (\"Radial Basis Function\"). El modelo SVC de Scikit-learn tiene un nº de kernel disponibles, y en concreto el kernel gaussiano no está entre ellos. Sin embargo, este kernel RBF está muy relacionado con él puesto que también parte de una clasificación \"radial\", y en proyectos reales es una implementación que puede ser más eficiente y tener más rendimiento que el kernel gaussiano, más simple.\n",
    "\n",
    "Por ello, en lugar del kernel gaussiano, usaremos el RBF.\n",
    "Este kernel para SVM tiene 2 parámetros:\n",
    "- *C*: La inversa del parámetro de regularización. Para valores mayores de *C*, se aceptará un margen entre clases menor si la función de decisión clasifica mejor los ejemplos de entrenamiento. Valores menores de *C* intentarán incrementar el margen entre clases, con una decisión de función más simple por lo tanto, con el coste de una posible menor precisión.\n",
    "- *Gamma*: Define lo lejos que llega la influencia de cada ejemplo, o la inversa del radio de influencia de los ejemplos seleccionados por el modelo como landmarks. Valores menores significarán una influencia que llegue más lejos, y valores mayores una influencia que llegue mucho menos lejos.\n",
    "\n",
    "Vamos a optimizar ambos parámetros usando validación cruzada.\n",
    "\n",
    "Como referencia para este ejercicio puedes usar estos enlaces de la documentación:\n",
    "- [SVM: Classification](https://scikit-learn.org/stable/modules/svm.html#classification)\n",
    "- [skelarn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "- [RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)\n",
    "- [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html)\n",
    "- [Non-linear SVM](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importa todos los módulos necesarios en esta celda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético de clasificación binaria\n",
    "\n",
    "Crea un dataset para clasificación de 2 clases con [sklearn.datasets.make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html).\n",
    "\n",
    "Recuerda usar parámetros que luego podamos modificar para el nº de ejemplos, características y clases, si queremos que esté desordenado o no, un estado aleatorio inicial constante, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Crea un dataset sintético para clasificación binaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Preprocesa los datos:\n",
    "- Reordénalos aleatoriamente.\n",
    "- Normalízalos.\n",
    "- Divídelos en subsets de entrenamiento y test (usaremos CV por K-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena los datos aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza los datos si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divídelos en subsets de entrenamiento, CV y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrena un modelo de clasificación por SVM inicial\n",
    "\n",
    "Para comprobar el funcionamiento de nuestro clasificador SVC antes de optimizarlo por validación cruzada, vamos a entrenar un modelo inicial sobre el subset de entrenamiento y validarlo sobre el subset de test.\n",
    "\n",
    "Recuerda usar la función [decision_function_shape](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification) para usar el esquema \"uno contra el resto\" (\"ovr\").\n",
    "\n",
    "Usa los valores por defecto de *C* y *gamma* para no influir sobre su regularización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de SVC sin modificar los parámetros de regularización sobre el subset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el modelo con su score() sobre el subset de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma muy gráfica de comprender mejor cómo trabajan los SVM y comprobar la precisión de tu modelo es representar el hiper-plano que ahora separa las clases, cuyo margen con las clases intentamos maximizar.\n",
    "\n",
    "Para representarlo, recuerda que puedes seguir el ejemplo de [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html) y modificar su código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el hiper-plano de separación con el margen de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizar los hiper-parámetros de regularización por validación cruzada\n",
    "\n",
    "Ahora vamos a usar de nuevo [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) para optimizar nuestros hiper-parámetros *C* y *gamma* por K-fold.\n",
    "\n",
    "Queremos optimizar dichos parámetros, 2 a la vez en esta ocasión, y representar sus posibles valores de una forma visual.\n",
    "\n",
    "Un ejemplo muy interesante que referenciábamos es [RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html).\n",
    "\n",
    "Modifica su código para optimizar nuestro modelo sobre nuestro dataset sintético usando K-fold para optimizar *C* y *gamma*. Puedes usar el mismo rango logarítmico de valores para estos hiper-parámetros propuesto en el ejercicio o modificarlo para encontrar uno adecuado a tu dataset sintético.\n",
    "\n",
    "*Nota*: Recuerda que hemos preprocesado el dataset previamente siguiendo nuestros métodos habituales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optimiza los hiper-parámetros de SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: A veces es una buena idea dividir el código en celdas diferentes para poder modificarlas y reejecutarlas independientemente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa los efectos de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo finalmente sobre el subset de test\n",
    "- Muestra los coeficientes e intercept del mejor modelo.\n",
    "- Evalúa el mejor modelo sobre el subset de test inicial.\n",
    "- Representa las predicciones de las clases para comprobar los aciertos, fallos y el margen entre clases en el nuevo hiper-plano.\n",
    "\n",
    "Para representar las predicciones y el hiper-plano de margen entre clases, puedes volver a usar el código con el que evaluaste el modelo inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evalúa el mejor modelo sobre el subset de test inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa las predicciones, comprueba la precisión y el margen entre clases"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
