{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística: Clasificación multiclase\n",
    "\n",
    "Una vez implementado el entrenamiento completo de un modelo de regresión logística o clasificación binaria (2 clases), vamos a repetir el mismo ejemplo pero para \n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético para regresión logística multiclase\n",
    "- Preprocesar los datos.\n",
    "- Entrenar el modelo sobre el subset de entrenamiento y comprobar su idoneidad.\n",
    "- Hallar el parámetro de regularización *lambda* óptimo por CV.\n",
    "- Realizar prediccioes sobre nuevos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético para regresión logística multiclase\n",
    "\n",
    "Vamos a crear un dataset sintético de 3 clases para esta implementación completa.\n",
    "\n",
    "Para ello, crea un dataset sintético para regresión logística con término de bias y error de forma manual (para tener disponible *Theta_verd*) con una plantilla de código ligeramente diferente a la que has usado en el último ejercicio:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementa la función de activación sigmoide\n",
    "\n",
    "Copia tu función de ejercicios anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la función sigmoide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la clasificación multiclase vamos a calcular la Y de una forma diferente:\n",
    "Y tendrá unas dimensiones 2D de (clases x m), para representar todas las clases posibles. A esta codificación de p. ej. *[0, 0, 1]* la llamamos **one-hot encoding**.\n",
    "\n",
    "- Para cada ejemplo y clase, calcula el sigmoide con *Theta_verd* y *X.\n",
    "- Transforma los valores de Y para que sean 0, y 1 en el valor máx. del sigmoide.\n",
    "- Por útlimo, transforma en 1 el valor de la clase con un valor máx. del sigmoide, y en 0 los valores del resto de clases.\n",
    "\n",
    "Para introducir un término de error, recorre todos los valores de *Y* y, con un % de error aleatorio, modifica la clase de dicho ejemplo a una clase aleatoria.\n",
    "\n",
    "*Nota*: Cuidado, como por simplificar la implementación no cambiamos la clase de dicho % de ejemplos a otra diferente, sino que escogemos una al azar, no significa que dicho vayamos a tener dicho % de ejemplos incorrectos, sino que tendremos 1/nº clases, ya que será nuestra probabilidad de volver a escoger el mismo valor de *Y* para dicho ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético con término de bias y error de forma manual\n",
    "# Ya que vamos a entrenar tantos modelos, generamos un dataset \"pequeño\" para que se entrenen rápido\n",
    "# Si lo necesitas, puedes hacerlo más pequeño aún, o si quieres más precisión y un reto más real, ampliarlo\n",
    "m = 1000\n",
    "n = 2\n",
    "clases = 3\n",
    "\n",
    "# Genera un array 2D m x n con valores aleatorios entre -1 y 1\n",
    "# Insértale el término de bias como una primera columna de 1s\n",
    "X = [...]\n",
    "\n",
    "# Genera un array de theta 2D de (clases x n + 1) valores aleatorios\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Y tendrá unas dimensiones 2D de (clases x m)\n",
    "# Calcula la Y con el sigmoide y transforma sus valores en 0 o 1\n",
    "for c in range(clases):\n",
    "    Y[...] = sigmoid([...])\n",
    "    \n",
    "for j in range(m):\n",
    "    Y[...] = [...]\n",
    "\n",
    "# Para introducir un término de error, recorre todos los valores de Y y, con un % de error aleatorio, modifica\n",
    "# la clase elegida de dicho ejemplo por una clase aleatoria\n",
    "error = 0.15\n",
    "\n",
    "for j in range(m):\n",
    "    # Si un nº al azar es menor o igual que error\n",
    "    if [...]:\n",
    "        # Asigna una clase escogida aleatoriamente\n",
    "        Y[...] = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar:')\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Al igual que hacíamos para la regresión lineal, vamos a preprocesar los datos completamente, siguiendo los 3 pasos habituales:\n",
    "\n",
    "- Reordenarlos aleatoriamente.\n",
    "- Normalizarlos.\n",
    "- Dividirlos en subsets de entrenamiento, CV y test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordenar el dataset aleatoriamente\n",
    "\n",
    "Reordena los datos del dataset *X* e *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente el dataset\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Si lo prefieres, puedes usar la función de conveniencia de sklearn.utils.shuffle\n",
    "# Usa un estado aleatorio inicial de 42, para mantener la reproducibilidad\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar el dataset\n",
    "\n",
    "Implementa la función de normalización y normaliza el dataset de ejemplos *X*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "def normalize(x, mu, std):\n",
    "    \"\"\" Normaliza un dataset con ejemplos X\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los ejemplos, sin término de bias\n",
    "    mu -- vector 1D de Numpy con la media de cada característica/columna\n",
    "    std -- vector 1D de Numpy con la desviación típica de cada característica/columna\n",
    "    \n",
    "    Devuelve:\n",
    "    x_norm -- array 2D de Numpy con los ejemplos, con sus características normalizadas\n",
    "    \"\"\"\n",
    "    return [...]\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Si habías modificado tu función *normalize* para que calculara y devolviera los valores de *mu* y *std*, puedes modificar esta celda para incluir tu código personalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento, CV y test\n",
    "\n",
    "Divide el dataset de *X* e *Y* en 3 subsets con el ratio habitual, 60%/20%/20%.\n",
    "\n",
    "Si tu nº de ejemplos es mucho más alto o bajo, siempre puedes modificar este ratio por otro como 50/25/25 o 80/10/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 3 subsets según los ratios indicados\n",
    "\n",
    "ratios = [60,20,20]\n",
    "print('Ratios:\\n', ratios, ratios[0] + ratios[1] + ratios[2])\n",
    "\n",
    "r = [0,0]\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r[0] = [...]\n",
    "r[1] = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_cv, X_test = [...]\n",
    "# ¡Cuidado con las nuevas dimensiones de Y!\n",
    "Y_train, Y_cv, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_cv.shape)\n",
    "print(Y_cv.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial para cada clase\n",
    "\n",
    "Para la clasificación multiclase, debemos entrenar un modelo diferente para cada clase. Por tanto, si tenemos 3 clases debemos entrenar 3 modelos diferentes.\n",
    "\n",
    "Cada modelo sólo considerará los valores de la variable objetivo relativos a su clase, sólo clasificará los ejemplos como pertenecientes a su clase o no (pertenecientes al resto).\n",
    "\n",
    "Para ello, sólo le proporcionaremos los valores de *Y* para dicha clase o columna. P. ej.,\n",
    "*Y* = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "\n",
    "- *Y* para el modelo 1: [0, 0, 1]\n",
    "- *Y* para el modelo 2: [0, 1, 0]\n",
    "- *Y* para el modelo 3: [1, 0, 0]\n",
    "\n",
    "Al igual que hacíamos en ejercicios anteriores, vamos a entrenar modelos iniciales para comprobar que nuestra implementación es correcta:\n",
    "\n",
    "- Entrena un modelo inicial sin regularización para cada clase.\n",
    "- Representa el histórico de la función de coste para comprobar su evolución para cada modelo.\n",
    "- Si es necesario, modifica cualquier parámetro y reentrena los modelos. Usarás dichos parámetros en siguientes puntos.\n",
    "\n",
    "Copia las celdas de ejercicios anteriores donde implementabas la función de coste y gradient descent regularizados para regresión logística, y la celda donde entrenabas el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia las celdas con las funciones de coste y gradient descent para clasificación regularizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena tus modelos sobre el subset de entrenamiento sin regularizar\n",
    "\n",
    "# Crea una theta inicial con un valor dado.\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "lambda_ = 0.\n",
    "e = 1e-3\n",
    "iter_ = 1e3\n",
    "\n",
    "print('Hiper-arámetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)\n",
    "\n",
    "# Inicializa unas variables para almacenar el resultado de cada modelo con las dimensiones adecuadas\n",
    "# Cuidado: los modelos pueden necesitar un nº de iteraciones hasta que convergen bastante dispar\n",
    "# Dale a j_train un tamaño para almacenar hasta el nº máx. de iteraciones\n",
    "j_train_ini = [...]\n",
    "theta_train = [...]\n",
    "\n",
    "t = time.time()\n",
    "for c in [...]:    # Itera sobre el nº de clases\n",
    "    print('\\nModelo para la clase nº:', c)\n",
    "    \n",
    "    theta_train = [...]    # Copia profunda de theta_ini para que no se modifique\n",
    "    \n",
    "    t_model = time.time()\n",
    "    j_train_ini[...], theta_train[...] = regularized_logistic_gradient_descent([...])\n",
    "    \n",
    "    print('Tiempo de entrenamiento para el modelo (s):', time.time() - t_model)\n",
    "    \n",
    "print('Tiempo de entrenamiento total (s):', time.time() - t)\n",
    "\n",
    "print('\\nCoste final del modelo para cada clase:')\n",
    "print()\n",
    "\n",
    "print('\\nTheta final del modelo para cada clase:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones para cada modelo\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title('Función de coste en cada clase')\n",
    "\n",
    "for c in range(clases):\n",
    "    plt.subplot(clases, 1, c + 1)\n",
    "    plt.xlabel('Iteraciones')\n",
    "    plt.ylabel('Coste en clase {}'.format(c))\n",
    "    plt.plot(j_train_ini[...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar la idoneidad de los modelos\n",
    "\n",
    "Revisa la precisión de tus modelos y modifica los parámetros para reentrenarlos si es necesario.\n",
    "\n",
    "Recuerda que si tu dataset es \"demasiado preciso\" puedes volver a la celda original e introducir un término de error superior.\n",
    "\n",
    "Por complejidad de una clasificación multiclase, no te pediremos que compruebes si los modelos pueden estar sufriendo desviación o sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallar el hiper-parámetro *lambda* óptimo por CV\n",
    "\n",
    "Del mismo modo que hemos hecho en ejercicios anteriores, vamos a optimizar nuestro parámetro de regularización por validación cruzada para cada uno de las clases y modelos.\n",
    "\n",
    "Para ello, para cada clase, vamos a entrenar un modelo diferente por cada valor de *lambda* a considerar sobre el subset de entrenamiento, y evaluar su error o coste final sobre el subset de CV.\n",
    "\n",
    "De nuevo, vamos a representar gráficamente el error de cada modelo vs el valor de *lambda* usado e implementar un código que elegirá automáticamente el modelo más óptimo de entre todos para cada clase.\n",
    "\n",
    "Recuerda entrenar todos tus modelos en igualdad de condiciones.\n",
    "\n",
    "Por tanto, ahora debes modificar el código de la celda anterior para no entrenar un modelo, como anteriormente, sino entrenar un modelo por cada una de las clases, por cada uno de los valores de *lambda* a considerar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo por cada valor de lambda diferente sobre X_train y evalúalo sobre X_cv\n",
    "# Los valores de lambda que considerábamos anteriormente eran:\n",
    "# lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "# Si lo prefieres, modifica el nº de valores lambda para no entrenar tantos modelos y que tarde tanto tiempo\n",
    "lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "\n",
    "# Completa el código para entrenar un modelo diferente para cada clase y valor de lambda sobre X_train\n",
    "# Almacena sus thetas y costes finales\n",
    "# Posteriormente, evalúa sus costes totales en el subset de CV\n",
    "\n",
    "# Almacena dicha información en los siguientes arrays\n",
    "# Cuidado con sus dimensiones necesarias\n",
    "j_train = [...]\n",
    "j_cv = [...]\n",
    "theta_cv = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el error final para cada valor de lambda con una gráfica por clase\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "# Completa con tu código\n",
    "for c in range(clases):\n",
    "    plt.subplot(clases, 1, c + 1)\n",
    "    \n",
    "    plt.title('Clase:', c)\n",
    "    plt.xlabel('Lambda')\n",
    "    plt.ylabel('Coste final')\n",
    "    plt.plot(j_train[...])\n",
    "    plt.plot(j_cv[...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escoger el mejor modelo para cada clase\n",
    "\n",
    "Copia el código de ejercicios anteriores y modifícalo para escoger el modelo con mayor precisión sobre el subset de CV para cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escoge los modelos y valores de lambda óptimos, con el menor error sobre el subset de CV\n",
    "\n",
    "# Itera sobre todas las combinaciones de theta y lambda y escoge las de menor coste en el subset de CV\n",
    "\n",
    "j_final = [...]\n",
    "theta_final = [...]\n",
    "lambda_final = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar los modelos sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo de cada clase sobre un subset de datos que no hemos usado para entrenarlos ni para escoger ningún hiper-parámetro.\n",
    "\n",
    "Para ello, vamos a calcular el coste o error total sobre el subset de test y comprobar gráficamente los resíduos sobre el mismo.\n",
    "\n",
    "Recuerda usar sólo las columnas de la *Y* que \"vería\" cada modelo, puesto que clasifica los ejemplos en función de si pertenecen a su clase o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error de los modelos sobre el subset de test usando la función de coste con las \n",
    "# correspondientes thetas y lambdas\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones de los modelos sobre el subset de test, calcula los resíduos y represéntalos\n",
    "\n",
    "# Recuerda usar la función sigmoide para transformar las predicciones\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonus*: Al igual que en el ejercicio anterior, además de los resíduos, *¿por qué no representas gráficamente también todas las predicciones sobre el subset de test para comprobar en cuántas de ellas acierta nuestro modelo?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestros modelos ya entrenado, optimizado y evaluado, lo único que nos queda es ponerlo en funcionamiento realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo para cada una de las clases, o lo que es lo mismo, por cada uno de los 3 modelos.\n",
    "- Escoger la clase final como la clase con mayor valor de *Y* tras el sigmoide, puesto que en algunos casos varios modelos pueden quere clasificar el ejemplo en su clase asociada a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias y error aleatorio\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Para comparar, antes de normalizar los datos, usa la Theta_verd para ver cuál sería la clase real asociada\n",
    "Y_verd = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas originales\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo para cada modelo usando el sigmoide\n",
    "Y_pred = [...]\n",
    "\n",
    "# Escoge la clase final como la de mayor valor tras el sigmoide y transfórmala a un vector de 0s y 1s\n",
    "Y_pred = [...]\n",
    "\n",
    "# Compara la clase real asociada a dicho nuevo ejemplo y la clase predicha\n",
    "print('Clase real del nuevo ejemplo y clase predicha:')\n",
    "print(Y_verd)\n",
    "print(Y_pred)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
