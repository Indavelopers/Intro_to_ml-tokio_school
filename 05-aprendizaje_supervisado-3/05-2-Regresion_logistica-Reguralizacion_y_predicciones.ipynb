{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística: Regularización y predicciones\n",
    "\n",
    "Una vez implementada la función de coste y gradient descent regularizados, vamos a entrenar un modelo de regresión logística completo, comprobándolo por validación cruzada, evaluándolo sobre un subset de test y, finalmente, realizando predicciones sobre el mismo.\n",
    "\n",
    "En este ejercicio vamos a continuar implementando una clasificación entre 2 únicas clases. En el siguiente ejercicio resolveremos el problema de una clasificación multiclase.\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético para regresión logística.\n",
    "- Preprocesar los datos.\n",
    "- Entrenar el modelo sobre el subset de entrenamiento y comprobar su idoneidad.\n",
    "- Hallar el parámetro de regularización *lambda* óptimo por CV.\n",
    "- Realizar prediccioes sobre nuevos ejemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético para regresión logística\n",
    "\n",
    "Vamos a crear un dataset sintético de 2 únicas clases (0 y 1) para comprobar esta implementación de un modelo de clasificación binaria, entrenado completamente, paso a paso.\n",
    "\n",
    "Para ello, crea un dataset sintético para regresión logística con término de bias y error de forma manual (para tener disponible *Theta_verd*) con el código que has usado en el último ejercicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético con término de bias y error de forma manual\n",
    "m = 1000\n",
    "n = 2\n",
    "\n",
    "# Genera un array 2D m x n con valores aleatorios entre -1 y 1\n",
    "# Insértale el término de bias como una primera columna de 1s\n",
    "X = [...]\n",
    "\n",
    "# Genera un array de theta de n + 1 valores aleatorios\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Calcula Y en función de X y Theta_verd\n",
    "# Añádele un término de error modificable\n",
    "# Transforma Y a valores de 1. y 0. (float) cuando Y >= 0.5\n",
    "error = 0.20\n",
    "\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "Y = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar:')\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota importante*: El término de error en un dataset sintético de clasificación funciona de una forma diferente al de regresión lineal. En la regresión, simplemente modificábamos el valor de *Y* en un margen.\n",
    "\n",
    "Sin embargo, en la clasificación cuando introducimos ese error es antes de transformar ese valor numérico de *Y* a un valor de 0 o 1. Por tanto, si el término de error no hace que el valor numérico suba o baje de 0.5, la clase asociada a dicho ejemplo no cambiará.\n",
    "\n",
    "Por tanto, si ves que tu dataset es \"demasiado preciso\" para poder comprobar tu implementación de clasificación regularizada, puedes volver a este punto, incrementar el término de error y ejecutar el resto de celdas de nuevo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Al igual que hacíamos para la regresión lineal, vamos a preprocesar los datos completamente, siguiendo los 3 pasos habituales:\n",
    "\n",
    "- Reordenarlos aleatoriamente.\n",
    "- Normalizarlos.\n",
    "- Dividirlos en subsets de entrenamiento, CV y test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordenar el dataset aleatoriamente\n",
    "\n",
    "Reordena los datos del dataset *X* e *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente el dataset\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Si lo prefieres, puedes usar la función de conveniencia de sklearn.utils.shuffle\n",
    "# Usa un estado aleatorio inicial de 42, para mantener la reproducibilidad\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar el dataset\n",
    "\n",
    "Implementa la función de normalización y normaliza el dataset de ejemplos *X*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "def normalize(x, mu, std):\n",
    "    \"\"\" Normaliza un dataset con ejemplos X\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los ejemplos, sin término de bias\n",
    "    mu -- vector 1D de Numpy con la media de cada característica/columna\n",
    "    std -- vector 1D de Numpy con la desviación típica de cada característica/columna\n",
    "    \n",
    "    Devuelve:\n",
    "    x_norm -- array 2D de Numpy con los ejemplos, con sus características normalizadas\n",
    "    \"\"\"\n",
    "    return [...]\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Si habías modificado tu función *normalize* para que calculara y devolviera los valores de *mu* y *std*, puedes modificar esta celda para incluir tu código personalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento, CV y test\n",
    "\n",
    "Divide el dataset de *X* e *Y* en 3 subsets con el ratio habitual, 60%/20%/20%.\n",
    "\n",
    "Si tu nº de ejemplos es mucho más alto o bajo, siempre puedes modificar este ratio por otro como 50/25/25 o 80/10/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 3 subsets según los ratios indicados\n",
    "\n",
    "ratios = [60,20,20]\n",
    "print('Ratios:\\n', ratios, ratios[0] + ratios[1] + ratios[2])\n",
    "\n",
    "r = [0,0]\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r[0] = [...]\n",
    "r[1] = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_cv, X_test = [...]\n",
    "Y_train, Y_cv, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_cv.shape)\n",
    "print(Y_cv.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial sobre el subset de entrenamiento\n",
    "\n",
    "Al igual que hacíamos en ejercicios anteriores, vamos a entrenar un modelo inicial para comprobar que nuestra implementación y el dataset trabajan correctamente, y podremos entrenar un modelo por CV sin problema.\n",
    "\n",
    "Para ello, sigue los mismos pasos que seguiste para la regresión lineal:\n",
    "- Entrena un modelo inicial sin regularización.\n",
    "- Representa el histórico de la función de coste para comprobar su evolución.\n",
    "- Si es necesario, modifica cualquier parámetro y reentrena el modelo. Usarás dichos parámetros en siguientes puntos.\n",
    "\n",
    "Copia las celdas de ejercicios anteriores donde implementabas la función de coste y gradient descent regularizados para regresión logística, y la celda donde entrenabas el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia las celdas con las funciones de coste y gradient descent para clasificación regularizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia la celda donde entrenamos el modelo\n",
    "# Entrena tu modelo sobre el subset de entrenamiento sin regularizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones\n",
    "\n",
    "plt.figure(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar la idoneidad del modelo\n",
    "\n",
    "Revisa la precisión de tu modelo y modifica los parámetros para reentrenarlo si es necesario.\n",
    "\n",
    "Recuerda que si tu dataset es \"demasiado preciso\" puedes volver a la celda original e introducir un término de error superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar si existe desviación o sobreajuste\n",
    "\n",
    "Al igual que hacíamos en la regresión lineal, entrena 2 modelos en igualdad de condiciones, uno sobre los primeros datos del subset de entrenamiento y otro sobre el subset de CV (con el mismo nº de ejemplos en ambos casos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Establece una theta_ini e hiper-parámetros comunes a ambos modelos, para entrenarlos en igualdad de \n",
    "# condiciones\n",
    "\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "lambda_ = 0.\n",
    "e = 1e-3\n",
    "iter_ = 1e3\n",
    "\n",
    "print('Hiper-arámetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo sin regularización sobre los n primeros valores de X_train, donde n es el nº de\n",
    "# ejemplos disponibles en X_cv\n",
    "# Usa j_hist_train y theta_train como nombres de variables para distinguirlos del otro modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Comprueba que *theta_ini* no se ha modificado, o modifica tu código para que ambos modelos usen la misma *theta_ini*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Del mismo modo, entrena un modelo sin regularización sobre X_cv con los mismos parámetros\n",
    "# Recuerda usar j_hist_cv y theta_cv como nobmres de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora representa gráficamente ambas evoluciones sobre la misma gráfica, con colores diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa en una gráfica de líneas ambas evoluciones para compararlas\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "# Usa colores diferentes para ambas series, e indica una leyenda para distinguirlos\n",
    "plt.plot()\n",
    "plt.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que con un dataset sintético aleatorio es difícil que se diera un caso u otro, pero de esta forma podríamos apreciar dichos problemas de la siguiente forma:\n",
    "\n",
    "- Si el coste final en ambos subsets es alto, puede haber un problema de desviación o *bias*.\n",
    "- Si el coste final en ambos subsets es muy diferente entre sí, puede haber un problema de sobreajuste o *varianza*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallar el hiper-parámetro *lambda* óptimo por CV\n",
    "\n",
    "Del mismo modo que hemos hecho en ejercicios anteriores, vamos a optimizar nuestro parámetro de regularización por validación cruzada.\n",
    "\n",
    "Para ello vamos a entrenar un modelo diferente por cada valor de *lambda* a considerar sobre el subset de entrenamiento, y evaluar su error o coste final sobre el subset de CV.\n",
    "\n",
    "Vamos a representar gráficamente el error de cada modelo vs el valor de *lambda* usado e implementar un código que elegirá automáticamente el modelo más óptimo de entre todos.\n",
    "\n",
    "Recuerda entrenar todos tus modelos en igualdad de condiciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo por cada valor de lambda diferente sobre X_train y evalúalo sobre X_cv\n",
    "\n",
    "lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "\n",
    "# Completa el código para entrenar un modelo diferente para cada valor de lambda sobre X_train\n",
    "# Almacena su theta y error/coste final\n",
    "# Posteriormente, evalúa su coste total en el subset de CV\n",
    "\n",
    "# Almacena dicha información en los siguientes arrays, del mismo tamaño que lambdas\n",
    "j_train = [...]\n",
    "j_cv = [...]\n",
    "theta_cv = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el error final para cada valor de lambda\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "# Completa con tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escoger el mejor modelo\n",
    "\n",
    "Copia el código de ejercicios anteriores, modificándolo si es necesario, para escoger el modelo con mayor precisión sobre el subset de CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escoge el modelo y el valor de lambda óptimos, con el menor error sobre el subset de CV\n",
    "\n",
    "# Itera sobre todas las combinaciones de theta y lambda y escoge las de menor coste en el subset de CV\n",
    "\n",
    "j_final = [...]\n",
    "theta_final = [...]\n",
    "lambda_final = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar el modelo sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo sobre un subset de datos que no hemos usado para entrenarlo ni para escoger ningún hiper-parámetro.\n",
    "\n",
    "Para ello, vamos a calcular el coste o error total sobre el subset de test y comprobar gráficamente los resíduos sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error del modelo sobre el subset de test usando la función de coste con las correspondientes\n",
    "# theta y lambda\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones del modelo sobre el subset de test, calcula los resíduos y represéntalos\n",
    "\n",
    "# Recuerda usar la función sigmoide para transformar las predicciones\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bonus*: Además de los resíduos, *¿por qué no representas gráficamente también todas las predicciones sobre el subset de test para comprobar en cuántas de ellas acierta nuestro modelo?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestro modelo ya entrenado, optimizado y evaluado, lo único que nos queda es ponerlo en funcionamiento realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias y error aleatorio\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas originales\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo\n",
    "Y_pred = [...]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
